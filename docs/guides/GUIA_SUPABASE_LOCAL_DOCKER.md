# ğŸ³ GuÃ­a Completa: Supabase Local con Docker

**Proyecto:** ComerECO Web Application
**Fecha:** 2025-11-05
**VersiÃ³n:** 1.0
**Autor:** Equipo de Desarrollo

---

## ğŸ“‹ Tabla de Contenidos

1. [IntroducciÃ³n](#-introducciÃ³n)
2. [Â¿QuÃ© es Supabase Local?](#-quÃ©-es-supabase-local)
3. [Â¿Por quÃ© usar Docker?](#-por-quÃ©-usar-docker)
4. [Arquitectura Completa](#-arquitectura-completa)
5. [Servicios y Contenedores](#-servicios-y-contenedores)
6. [InstalaciÃ³n y ConfiguraciÃ³n](#-instalaciÃ³n-y-configuraciÃ³n)
7. [Comandos Esenciales](#-comandos-esenciales)
8. [Workflow de Desarrollo](#-workflow-de-desarrollo)
9. [Migrations: Local vs Cloud](#-migrations-local-vs-cloud)
10. [Puertos y URLs](#-puertos-y-urls)
11. [Casos de Uso PrÃ¡cticos](#-casos-de-uso-prÃ¡cticos)
12. [Troubleshooting](#-troubleshooting)
13. [Mejores PrÃ¡cticas](#-mejores-prÃ¡cticas)
14. [ComparaciÃ³n: Local vs Cloud](#-comparaciÃ³n-local-vs-cloud)
15. [FAQ](#-faq)

---

## ğŸ¯ IntroducciÃ³n

Esta guÃ­a explica en profundidad cÃ³mo funciona Supabase Local con Docker en el proyecto ComerECO, por quÃ© es esencial para el desarrollo, y cÃ³mo usarlo de manera efectiva.

### Â¿Para quiÃ©n es esta guÃ­a?

- âœ… Desarrolladores nuevos en el proyecto
- âœ… Desarrolladores que necesitan entender la infraestructura local
- âœ… Cualquiera que quiera entender cÃ³mo funciona Supabase bajo el capÃ³
- âœ… Equipos que necesitan configurar ambientes de desarrollo

---

## ğŸ—ï¸ Â¿QuÃ© es Supabase Local?

**Supabase Local** es una versiÃ³n completa de Supabase que corre en tu mÃ¡quina usando Docker.

### Concepto Clave

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Supabase Cloud (ProducciÃ³n)                   â”‚
â”‚  https://azjaehrdzdfgrumbqmuc.supabase.co      â”‚
â”‚                                                  â”‚
â”‚  - Usado por usuarios reales                    â”‚
â”‚  - Datos de producciÃ³n                          â”‚
â”‚  - Costos por uso                               â”‚
â”‚  - Requiere internet                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†•ï¸
               (sincronizaciÃ³n)
                    â†•ï¸
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Supabase Local (Desarrollo)                    â”‚
â”‚  http://127.0.0.1:54321                         â”‚
â”‚                                                  â”‚
â”‚  - Solo en tu mÃ¡quina                           â”‚
â”‚  - Datos de prueba                              â”‚
â”‚  - Gratis e ilimitado                           â”‚
â”‚  - Funciona sin internet                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Â¿QuÃ© incluye?

Supabase Local NO es solo una base de datos. Incluye **TODO el stack**:

- ğŸ—„ï¸ PostgreSQL 17 (base de datos)
- ğŸ” GoTrue (autenticaciÃ³n)
- ğŸ“¡ PostgREST (API REST automÃ¡tica)
- âš¡ Realtime (WebSockets)
- ğŸ“¦ Storage (almacenamiento de archivos)
- ğŸ–¥ï¸ Studio (interfaz visual)
- ğŸ“§ Email testing
- ğŸš€ Edge Functions
- ğŸ“Š Analytics
- ğŸ›¡ï¸ API Gateway

---

## ğŸ‹ Â¿Por quÃ© usar Docker?

Docker empaqueta cada componente de Supabase en **contenedores aislados**.

### AnalogÃ­a Simple

Imagina Docker como un "empaque de viaje":

```
ğŸ“¦ Docker Container = Maleta sellada
   â”œâ”€â”€ Sistema operativo mini (Alpine Linux)
   â”œâ”€â”€ AplicaciÃ³n (PostgreSQL, PostgREST, etc.)
   â”œâ”€â”€ Dependencias necesarias
   â””â”€â”€ ConfiguraciÃ³n

âœ… Ventajas:
   - Abres la maleta = Todo funciona
   - No contamina tu sistema
   - Misma maleta funciona en cualquier mÃ¡quina
   - Puedes tener mÃºltiples maletas abiertas
```

### Beneficios EspecÃ­ficos

#### 1. **Aislamiento**
```bash
# Sin Docker:
npm install -g supabase-cli
# Instala Node.js, PostgreSQL, Go, Rust...
# Tu sistema se llena de dependencias

# Con Docker:
docker-compose up
# Todo queda en contenedores
# Tu sistema queda limpio
```

#### 2. **Consistencia**
```yaml
# Todos en el equipo usan:
postgres: 17.6.1.032  # Misma versiÃ³n
postgrest: v13.0.5    # Mismas APIs
gotrue: v2.180.0      # Mismo comportamiento
```

#### 3. **Portabilidad**
```bash
# En tu mÃ¡quina (Linux WSL):
docker-compose up âœ…

# En Mac de tu compaÃ±ero:
docker-compose up âœ…

# En servidor de staging:
docker-compose up âœ…
```

#### 4. **Facilidad de Limpieza**
```bash
# Eliminar TODO Supabase Local:
docker-compose down -v

# Tu sistema:
# - Sin rastros de PostgreSQL
# - Sin configuraciones huÃ©rfanas
# - Sin archivos basura
```

---

## ğŸ›ï¸ Arquitectura Completa

### Diagrama de Servicios

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TU APLICACIÃ“N                             â”‚
â”‚              (Next.js en http://localhost:3000)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â†“ (HTTP/WebSocket)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 KONG API GATEWAY                             â”‚
â”‚              (http://127.0.0.1:54321)                        â”‚
â”‚                                                               â”‚
â”‚  - Punto de entrada Ãºnico                                    â”‚
â”‚  - Ruteo a servicios internos                                â”‚
â”‚  - Rate limiting                                             â”‚
â”‚  - CORS handling                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚              â”‚
       â†“              â†“              â†“              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgRESTâ”‚  â”‚ GoTrue   â”‚  â”‚ Realtime â”‚  â”‚ Storage  â”‚
â”‚ (REST)   â”‚  â”‚ (Auth)   â”‚  â”‚ (WS)     â”‚  â”‚ (Files)  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚             â”‚             â”‚             â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   PostgreSQL    â”‚
          â”‚  (port 54322)   â”‚
          â”‚                 â”‚
          â”‚  - auth.users   â”‚
          â”‚  - public.*     â”‚
          â”‚  - storage.*    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de una Request

```
1. Tu app hace:
   fetch('http://127.0.0.1:54321/rest/v1/products')

2. Kong recibe:
   - Valida token JWT
   - Aplica rate limiting
   - Enruta a PostgREST

3. PostgREST:
   - Traduce a SQL: SELECT * FROM products
   - Valida RLS (Row Level Security)
   - Ejecuta query en PostgreSQL

4. PostgreSQL:
   - Ejecuta query
   - Aplica polÃ­ticas RLS
   - Retorna datos

5. PostgREST:
   - Formatea a JSON
   - Retorna a Kong

6. Kong:
   - Retorna a tu app
   - Logs en Vector/Logflare
```

---

## ğŸ›ï¸ Servicios y Contenedores

### 1. PostgreSQL (`supabase_db`)

**FunciÃ³n:** Base de datos principal

**Puerto:** `54322` (local) â†’ `5432` (interno)

**Imagen:** `public.ecr.aws/supabase/postgres:17.6.1.032`

#### Â¿QuÃ© hace?
- Almacena todos tus datos (users, products, requisitions, etc.)
- Ejecuta queries SQL
- Aplica RLS (Row Level Security)
- Ejecuta triggers y functions

#### Extensiones incluidas:
```sql
-- Ver extensiones instaladas
SELECT * FROM pg_extension;
```

Principales:
- `pgcrypto` - EncriptaciÃ³n
- `uuid-ossp` - GeneraciÃ³n de UUIDs
- `pg_stat_statements` - EstadÃ­sticas de queries
- `pg_trgm` - BÃºsqueda full-text
- `pgvector` - Vectores para AI/ML
- `pgmq` - Message Queue (colas)

#### Acceso directo:
```bash
# Conectar con psql
psql postgresql://postgres:postgres@127.0.0.1:54322/postgres

# O desde Docker
docker exec -it supabase_db_COMERECO-WEBAPP psql -U postgres

# Ver tablas
\dt

# Ver schemas
\dn

# Ver funciones
\df
```

#### Datos persistentes:
```bash
# Ver volumen
docker volume ls | grep supabase

# UbicaciÃ³n:
# /var/lib/docker/volumes/supabase_db_COMERECO-WEBAPP/_data

# Backup:
pg_dump postgresql://postgres:postgres@127.0.0.1:54322/postgres > backup.sql
```

---

### 2. Kong API Gateway (`supabase_kong`)

**FunciÃ³n:** Proxy y punto de entrada Ãºnico

**Puerto:** `54321` (local) â†’ `8000` (interno)

**Imagen:** `public.ecr.aws/supabase/kong:2.8.1`

#### Â¿QuÃ© hace?
- Recibe todas las requests
- Valida autenticaciÃ³n (JWT)
- Rutea a servicios internos
- Aplica rate limiting
- Maneja CORS

#### Rutas configuradas:
```
/rest/v1/*         â†’ PostgREST (port 3000)
/auth/v1/*         â†’ GoTrue (port 9999)
/realtime/v1/*     â†’ Realtime (port 4000)
/storage/v1/*      â†’ Storage (port 5000)
/graphql/v1/*      â†’ PostgREST GraphQL
```

#### Ejemplo de uso:
```javascript
// Todas estas requests van a Kong primero
const { data } = await supabase
  .from('products')  // â†’ Kong â†’ PostgREST â†’ PostgreSQL
  .select('*')

await supabase.auth.signIn()  // â†’ Kong â†’ GoTrue
```

---

### 3. PostgREST (`supabase_rest`)

**FunciÃ³n:** Auto-genera REST API desde tu schema SQL

**Puerto:** `3000` (solo interno)

**Imagen:** `public.ecr.aws/supabase/postgrest:v13.0.5`

#### Â¿QuÃ© hace?
```
Tu schema SQL:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CREATE TABLE    â”‚
â”‚ products (      â”‚
â”‚   id UUID,      â”‚
â”‚   name TEXT     â”‚
â”‚ );              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
PostgREST auto-genera:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GET    /products                â”‚
â”‚ POST   /products                â”‚
â”‚ PATCH  /products?id=eq.{uuid}   â”‚
â”‚ DELETE /products?id=eq.{uuid}   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### CaracterÃ­sticas:
- **Filtros avanzados:**
  ```javascript
  // WHERE name LIKE '%pastilla%' AND price > 10
  .select('*')
  .ilike('name', '%pastilla%')
  .gt('price', 10)
  ```

- **Joins automÃ¡ticos:**
  ```javascript
  // SELECT * FROM requisitions
  // LEFT JOIN companies ON requisitions.company_id = companies.id
  .select('*, companies(*)')
  ```

- **RLS integrado:**
  ```sql
  -- PostgREST ejecuta queries con:
  SET LOCAL role = 'authenticated';
  SET LOCAL request.jwt.claim.sub = '{user_id}';
  ```

#### Ver logs:
```bash
docker logs supabase_rest_COMERECO-WEBAPP -f
```

---

### 4. GoTrue (`supabase_auth`)

**FunciÃ³n:** Sistema de autenticaciÃ³n

**Puerto:** `9999` (solo interno)

**Imagen:** `public.ecr.aws/supabase/gotrue:v2.180.0`

#### Â¿QuÃ© hace?
- Registro de usuarios
- Login/Logout
- RecuperaciÃ³n de contraseÃ±as
- OAuth (Google, GitHub, etc.)
- Magic links
- GestiÃ³n de sesiones (JWT)

#### Flujo de autenticaciÃ³n:
```
1. User hace login:
   POST /auth/v1/token
   Body: { email, password }

2. GoTrue:
   - Valida credenciales contra auth.users
   - Genera JWT (expira en 1 hora)
   - Retorna: { access_token, refresh_token }

3. Tu app guarda token:
   localStorage.setItem('token', access_token)

4. Requests subsecuentes:
   Headers: { Authorization: 'Bearer {token}' }

5. Kong valida token:
   - Verifica firma
   - Extrae user_id
   - Pasa a PostgREST

6. PostgreSQL usa user_id para RLS:
   auth.uid() = {user_id_from_token}
```

#### Tabla auth.users:
```sql
-- Ver usuarios
SELECT id, email, created_at, confirmed_at
FROM auth.users;

-- Crear usuario manualmente (testing)
INSERT INTO auth.users (
  instance_id,
  id,
  aud,
  role,
  email,
  encrypted_password,
  email_confirmed_at,
  created_at,
  updated_at
) VALUES (
  '00000000-0000-0000-0000-000000000000',
  gen_random_uuid(),
  'authenticated',
  'authenticated',
  'test@example.com',
  crypt('password123', gen_salt('bf')),
  NOW(),
  NOW(),
  NOW()
);
```

---

### 5. Realtime (`supabase_realtime`)

**FunciÃ³n:** WebSockets para cambios en tiempo real

**Puerto:** `4000` (solo interno)

**Imagen:** `public.ecr.aws/supabase/realtime:v2.57.3`

#### Â¿QuÃ© hace?
```javascript
// Escucha cambios en productos
const subscription = supabase
  .channel('products-changes')
  .on('postgres_changes', {
    event: '*',
    schema: 'public',
    table: 'products'
  }, (payload) => {
    console.log('Cambio detectado:', payload)
  })
  .subscribe()
```

#### Eventos soportados:
- `INSERT` - Nuevo registro
- `UPDATE` - Registro modificado
- `DELETE` - Registro eliminado
- `*` - Todos los eventos

#### Casos de uso:
```javascript
// 1. Chat en tiempo real
supabase
  .channel('messages')
  .on('postgres_changes', {
    event: 'INSERT',
    schema: 'public',
    table: 'messages'
  }, (payload) => {
    addMessageToUI(payload.new)
  })
  .subscribe()

// 2. Notificaciones de requisiciones
supabase
  .channel('requisitions')
  .on('postgres_changes', {
    event: 'UPDATE',
    schema: 'public',
    table: 'requisitions',
    filter: 'user_id=eq.' + userId
  }, (payload) => {
    showNotification('Tu requisiciÃ³n cambiÃ³ de estado')
  })
  .subscribe()

// 3. Presence (quiÃ©n estÃ¡ online)
const channel = supabase.channel('online-users')

channel
  .on('presence', { event: 'sync' }, () => {
    const state = channel.presenceState()
    console.log('Usuarios online:', Object.keys(state).length)
  })
  .subscribe(async (status) => {
    if (status === 'SUBSCRIBED') {
      await channel.track({ user_id: userId, online_at: new Date() })
    }
  })
```

#### Habilitar Realtime en tabla:
```sql
-- Por defecto, Realtime estÃ¡ deshabilitado
ALTER PUBLICATION supabase_realtime ADD TABLE products;

-- Ver tablas con Realtime habilitado
SELECT * FROM pg_publication_tables
WHERE pubname = 'supabase_realtime';
```

---

### 6. Storage API (`supabase_storage`)

**FunciÃ³n:** Almacenamiento de archivos (imÃ¡genes, PDFs, etc.)

**Puerto:** `5000` (solo interno)

**Imagen:** `public.ecr.aws/supabase/storage-api:v1.28.2`

#### Â¿QuÃ© hace?
- Upload/Download de archivos
- Genera URLs pÃºblicas o privadas
- Redimensiona imÃ¡genes automÃ¡ticamente
- S3-compatible

#### Estructura:
```
storage.buckets        â†’ Contenedores (ej: avatars, documents)
  â”œâ”€â”€ id
  â”œâ”€â”€ name
  â”œâ”€â”€ public (bool)
  â””â”€â”€ file_size_limit

storage.objects        â†’ Archivos individuales
  â”œâ”€â”€ id
  â”œâ”€â”€ bucket_id
  â”œâ”€â”€ name               (ej: user/123/avatar.jpg)
  â”œâ”€â”€ owner              (user_id)
  â””â”€â”€ metadata
```

#### Ejemplo de uso:
```javascript
// 1. Crear bucket
await supabase
  .storage
  .createBucket('product-images', {
    public: true,
    fileSizeLimit: 5242880  // 5MB
  })

// 2. Upload archivo
const file = document.querySelector('input[type="file"]').files[0]
const { data, error } = await supabase
  .storage
  .from('product-images')
  .upload(`products/${productId}/main.jpg`, file)

// 3. Get URL pÃºblica
const { data } = supabase
  .storage
  .from('product-images')
  .getPublicUrl(`products/${productId}/main.jpg`)

console.log(data.publicUrl)
// http://127.0.0.1:54321/storage/v1/object/public/product-images/products/123/main.jpg

// 4. Redimensionar imagen
const url = supabase
  .storage
  .from('product-images')
  .getPublicUrl(`products/${productId}/main.jpg`, {
    transform: {
      width: 300,
      height: 300,
      resize: 'cover'
    }
  })
```

#### RLS en Storage:
```sql
-- Permitir upload solo a dueÃ±os
CREATE POLICY "Users can upload own files"
ON storage.objects FOR INSERT
TO authenticated
WITH CHECK (
  bucket_id = 'avatars' AND
  (storage.foldername(name))[1] = auth.uid()::text
);

-- Permitir lectura pÃºblica
CREATE POLICY "Anyone can view avatars"
ON storage.objects FOR SELECT
TO public
USING (bucket_id = 'avatars');
```

---

### 7. Supabase Studio (`supabase_studio`)

**FunciÃ³n:** Interfaz visual (igual que supabase.com/dashboard)

**Puerto:** `54323` (acceso local)

**Imagen:** `public.ecr.aws/supabase/studio:2025.10.27-sha-85b84e0`

#### Â¿QuÃ© puedes hacer?

1. **Table Editor**
   - Ver/editar datos
   - Crear/modificar tablas
   - Gestionar relaciones

2. **SQL Editor**
   - Ejecutar queries
   - Ver historial
   - Guardar snippets

3. **Authentication**
   - Ver usuarios
   - Gestionar policies
   - Configurar providers

4. **Storage**
   - Ver buckets
   - Upload/delete archivos
   - Gestionar polÃ­ticas

5. **Database**
   - Ver schema
   - Triggers
   - Extensions
   - ReplicaciÃ³n

6. **API Docs**
   - DocumentaciÃ³n auto-generada
   - Ejemplos de cÃ³digo
   - OpenAPI spec

#### Acceso:
```bash
# Abrir Studio
open http://127.0.0.1:54323

# Login (primera vez):
# - No requiere password en local
# - Click en "Continue with local development"
```

---

### 8. Mailpit (`supabase_inbucket`)

**FunciÃ³n:** Email testing (captura emails enviados)

**Puerto:** `54324` (acceso local)

**Imagen:** `public.ecr.aws/supabase/mailpit:v1.22.3`

#### Â¿QuÃ© hace?
En desarrollo, los emails NO se envÃ­an realmente. Mailpit los captura:

```javascript
// Tu cÃ³digo envÃ­a email:
await supabase.auth.resetPasswordForEmail('user@example.com')

// Email NO llega a user@example.com
// En su lugar, aparece en: http://127.0.0.1:54324
```

#### Ver emails:
```bash
# 1. Abrir Mailpit UI
open http://127.0.0.1:54324

# VerÃ¡s lista de emails capturados:
# - ConfirmaciÃ³n de registro
# - Reset password
# - Magic links
# - Invitaciones
```

#### Usar magic link en desarrollo:
```bash
# 1. Ejecuta:
await supabase.auth.signInWithOtp({ email: 'test@example.com' })

# 2. Ve a Mailpit: http://127.0.0.1:54324

# 3. Abre el email, copia el link

# 4. PÃ©galo en el navegador
# Formato: http://localhost:3000/auth/confirm?token=xxxxx
```

---

### 9. Postgres Meta (`supabase_pg_meta`)

**FunciÃ³n:** API para metadata de PostgreSQL

**Puerto:** `8080` (solo interno)

**Imagen:** `public.ecr.aws/supabase/postgres-meta:v0.93.1`

#### Â¿QuÃ© hace?
Expone informaciÃ³n de PostgreSQL vÃ­a REST API para Studio:

```bash
# Ejemplos de lo que hace:
GET /tables          â†’ Lista de tablas
GET /columns?table=products  â†’ Columnas de tabla
GET /roles           â†’ Roles de PostgreSQL
GET /extensions      â†’ Extensiones instaladas
GET /policies        â†’ RLS policies
```

Studio usa esto para mostrar la UI.

---

### 10. Edge Runtime (`supabase_edge_runtime`)

**FunciÃ³n:** Ejecuta Edge Functions (Deno)

**Puerto:** `8081` (solo interno)

**Imagen:** `public.ecr.aws/supabase/edge-runtime:v1.69.15`

#### Â¿QuÃ© hace?
Corre funciones serverless escritas en TypeScript/Deno:

```typescript
// supabase/functions/hello/index.ts
import { serve } from 'https://deno.land/std@0.177.0/http/server.ts'

serve(async (req) => {
  const { name } = await req.json()

  return new Response(
    JSON.stringify({ message: `Hello ${name}!` }),
    { headers: { 'Content-Type': 'application/json' } }
  )
})
```

```bash
# Deploy local
supabase functions deploy hello

# Invocar
curl -X POST http://127.0.0.1:54321/functions/v1/hello \
  -H "Content-Type: application/json" \
  -d '{"name":"World"}'
```

---

### 11. Vector (`supabase_vector`)

**FunciÃ³n:** RecolecciÃ³n de logs

**Imagen:** `public.ecr.aws/supabase/vector:0.28.1-alpine`

#### Â¿QuÃ© hace?
- Agrega logs de todos los servicios
- Los envÃ­a a Logflare (Analytics)
- Permite bÃºsqueda centralizada

---

### 12. Logflare (`supabase_analytics`)

**FunciÃ³n:** Dashboard de logs y analytics

**Puerto:** `54327` (acceso local)

**Imagen:** `public.ecr.aws/supabase/logflare:1.23.2`

#### Â¿QuÃ© hace?
```bash
# Ver logs en tiempo real
open http://127.0.0.1:54327

# VerÃ¡s:
# - Queries SQL ejecutados
# - Requests API
# - Errores
# - Performance metrics
```

Ãštil para debugging.

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos

```bash
# 1. Instalar Docker
# Ubuntu/WSL:
curl -fsSL https://get.docker.com | sh
sudo usermod -aG docker $USER
newgrp docker

# Mac:
# Descargar Docker Desktop: https://docker.com/products/docker-desktop

# Windows:
# Usar WSL2 + Docker Desktop

# 2. Verificar instalaciÃ³n
docker --version
docker-compose --version

# 3. Instalar Supabase CLI
npm install -g supabase

# Verificar
supabase --version
```

### Inicializar Proyecto

```bash
# 1. Clonar repo (si aÃºn no lo tienes)
git clone <tu-repo>
cd COMERECO-WEBAPP

# 2. Verificar carpeta supabase existe
ls supabase/
# DeberÃ­as ver:
# - config.toml
# - migrations/
# - seed.sql

# 3. Iniciar Supabase Local
supabase start

# Primera vez toma ~5 minutos:
# - Descarga imÃ¡genes Docker (~2GB)
# - Crea contenedores
# - Aplica migrations
# - Carga seed data
```

### ConfiguraciÃ³n Inicial

```bash
# 1. Ver status
supabase status

# Output:
#     API URL: http://127.0.0.1:54321
#     DB URL: postgresql://postgres:postgres@127.0.0.1:54322/postgres
#     Studio URL: http://127.0.0.1:54323
#     Anon key: eyJh...
#     Service role key: eyJh...

# 2. Copiar keys a .env.local
cat > .env.local <<EOF
NEXT_PUBLIC_SUPABASE_URL=http://127.0.0.1:54321
NEXT_PUBLIC_SUPABASE_ANON_KEY=<anon-key-de-status>
SUPABASE_SERVICE_ROLE_KEY=<service-key-de-status>
DATABASE_URL=postgresql://postgres:postgres@127.0.0.1:54322/postgres
EOF

# 3. Abrir Studio
open http://127.0.0.1:54323
```

### Verificar Todo Funciona

```bash
# 1. Test conexiÃ³n DB
psql postgresql://postgres:postgres@127.0.0.1:54322/postgres -c "SELECT version();"

# 2. Test API
curl http://127.0.0.1:54321/rest/v1/ \
  -H "apikey: <anon-key>"

# 3. Ver containers corriendo
docker ps

# DeberÃ­as ver ~12 contenedores
```

---

## ğŸ’» Comandos Esenciales

### Comandos Supabase CLI

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CICLO DE VIDA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Iniciar todos los servicios
supabase start

# Detener (datos persisten)
supabase stop

# Detener y eliminar datos
supabase stop --no-backup

# Reiniciar
supabase restart

# Ver status
supabase status

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MIGRATIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Crear nueva migration
supabase migration new add_products_table

# Ver migrations pendientes
supabase migration list

# Aplicar migrations (reset completo)
supabase db reset

# Diff: Ver cambios en DB vs migrations
supabase db diff

# Diff y crear migration automÃ¡tica
supabase db diff -f new_changes

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SINCRONIZACIÃ“N CON CLOUD
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Linkear con proyecto cloud
supabase link --project-ref <project-ref>

# Ver project-ref
supabase projects list

# Pull: Traer schema de cloud a local
supabase db pull

# Push: Subir migrations a cloud
supabase db push

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TESTING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ejecutar tests
supabase test db

# Ver logs en tiempo real
supabase logs --tail

# Ver logs de servicio especÃ­fico
supabase logs postgres --tail
supabase logs auth --tail
supabase logs storage --tail

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIONES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Crear funciÃ³n
supabase functions new my-function

# Deploy local
supabase functions deploy my-function

# Invocar
supabase functions invoke my-function \
  --body '{"name":"test"}'

# Ver logs de funciones
supabase functions logs my-function

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GENERACIÃ“N DE TIPOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Generar types TypeScript
supabase gen types typescript --local > types/supabase.ts

# Desde cloud
supabase gen types typescript --linked > types/supabase.ts
```

### Comandos Docker

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VER ESTADO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ver todos los contenedores
docker ps -a

# Ver solo contenedores de Supabase
docker ps | grep supabase

# Ver uso de recursos
docker stats

# Ver imÃ¡genes descargadas
docker images | grep supabase

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LOGS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Logs de contenedor especÃ­fico
docker logs supabase_db_COMERECO-WEBAPP

# Seguir logs en tiempo real
docker logs -f supabase_db_COMERECO-WEBAPP

# Ãšltimas 100 lÃ­neas
docker logs --tail 100 supabase_db_COMERECO-WEBAPP

# Con timestamps
docker logs -t supabase_db_COMERECO-WEBAPP

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ACCESO A CONTENEDORES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Entrar a shell de contenedor
docker exec -it supabase_db_COMERECO-WEBAPP bash

# Ejecutar comando en contenedor
docker exec supabase_db_COMERECO-WEBAPP psql -U postgres -c "SELECT COUNT(*) FROM auth.users"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LIMPIEZA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Detener todos los contenedores de Supabase
docker stop $(docker ps -q --filter "name=supabase")

# Eliminar contenedores detenidos
docker container prune

# Eliminar imÃ¡genes no usadas
docker image prune -a

# Ver volÃºmenes
docker volume ls | grep supabase

# Eliminar volumen (Â¡CUIDADO! Pierdes datos)
docker volume rm supabase_db_COMERECO-WEBAPP

# Limpieza completa (libera espacio)
docker system prune -a --volumes

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TROUBLESHOOTING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Reiniciar contenedor especÃ­fico
docker restart supabase_db_COMERECO-WEBAPP

# Ver health status
docker inspect supabase_db_COMERECO-WEBAPP | grep -A 10 Health

# Ver configuraciÃ³n de red
docker network inspect supabase_network_COMERECO-WEBAPP

# Ver variables de entorno
docker exec supabase_db_COMERECO-WEBAPP env
```

### Comandos PostgreSQL

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONEXIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Conectar con psql
psql postgresql://postgres:postgres@127.0.0.1:54322/postgres

# O desde variable
export DATABASE_URL="postgresql://postgres:postgres@127.0.0.1:54322/postgres"
psql $DATABASE_URL

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DENTRO DE psql (\comandos)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Listar bases de datos
\l

# Conectar a otra DB
\c postgres

# Listar schemas
\dn

# Listar tablas (schema actual)
\dt

# Listar tablas (todos los schemas)
\dt *.*

# Ver tabla especÃ­fica
\d products

# Listar funciones
\df

# Listar triggers
SELECT * FROM pg_trigger;

# Listar polÃ­ticas RLS
\dp products

# Ver usuarios/roles
\du

# Ver tamaÃ±o de tablas
SELECT
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

# Salir
\q

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# QUERIES ÃšTILES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ver migrations aplicadas
SELECT * FROM supabase_migrations.schema_migrations
ORDER BY version;

# Ver usuarios auth
SELECT id, email, created_at, confirmed_at
FROM auth.users;

# Ver sesiones activas
SELECT *
FROM auth.sessions
WHERE expires_at > NOW();

# Ver queries lentos
SELECT
  query,
  calls,
  total_time,
  mean_time,
  max_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 10;

# Ver conexiones activas
SELECT
  datname,
  usename,
  application_name,
  client_addr,
  state,
  query
FROM pg_stat_activity
WHERE state = 'active';

# Vacuumar tabla (optimizar)
VACUUM ANALYZE products;

# Recrear Ã­ndices
REINDEX TABLE products;

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BACKUP Y RESTORE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Backup completo
pg_dump postgresql://postgres:postgres@127.0.0.1:54322/postgres > backup_$(date +%Y%m%d).sql

# Backup solo schema
pg_dump --schema-only postgresql://postgres:postgres@127.0.0.1:54322/postgres > schema.sql

# Backup solo datos
pg_dump --data-only postgresql://postgres:postgres@127.0.0.1:54322/postgres > data.sql

# Backup tabla especÃ­fica
pg_dump -t products postgresql://postgres:postgres@127.0.0.1:54322/postgres > products_backup.sql

# Restore
psql postgresql://postgres:postgres@127.0.0.1:54322/postgres < backup.sql
```

---

## ğŸ”„ Workflow de Desarrollo

### Flujo Completo: Idea â†’ ProducciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. DESARROLLO LOCAL                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Iniciar Supabase Local
cd ~/COMERECO-WEBAPP
supabase start

# Abrir Studio
open http://127.0.0.1:54323

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. CREAR CAMBIOS EN DB                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# OpciÃ³n A: SQL Editor en Studio
# - Escribir SQL
# - Ejecutar
# - Ver resultados inmediatos

# OpciÃ³n B: Crear migration
supabase migration new add_restock_rules

# Editar: supabase/migrations/20250105_add_restock_rules.sql
CREATE TABLE restock_rules (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  product_id UUID REFERENCES products(id),
  min_stock INTEGER NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

ALTER TABLE restock_rules ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can view own company rules"
ON restock_rules FOR SELECT
TO authenticated
USING (
  product_id IN (
    SELECT id FROM products
    WHERE company_id = auth.jwt()->>'company_id'::uuid
  )
);

# Aplicar migration
supabase db reset

# Verificar
psql $DATABASE_URL -c "\d restock_rules"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. DESARROLLAR FEATURES EN NEXT.JS             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Terminal 1: Supabase (ya corriendo)
supabase start

# Terminal 2: Next.js dev server
npm run dev

# Terminal 3: Ver logs Supabase
supabase logs --tail

# Desarrollar features:
# - src/app/restock-rules/page.tsx
# - src/lib/api/restock-rules.ts

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. TESTING                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Test manual en http://localhost:3000
# - Crear reglas
# - Editar reglas
# - Verificar RLS funciona

# Test de DB directo
psql $DATABASE_URL
> INSERT INTO restock_rules (product_id, min_stock)
  VALUES ('...', 10);
> SELECT * FROM restock_rules;

# Ver requests en Studio Logs
open http://127.0.0.1:54323/project/default/logs/explorer

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. COMMIT CHANGES                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

git add supabase/migrations/
git add src/app/restock-rules/
git commit -m "feat: Add restock rules management"
git push origin feature/restock-rules

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. PUSH A STAGING (opcional)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Link a proyecto staging
supabase link --project-ref staging-ref

# Push migrations
supabase db push

# Deploy app a Vercel staging
git push origin staging

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. PUSH A PRODUCCIÃ“N                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Link a producciÃ³n
supabase link --project-ref prod-ref

# Verificar migrations pendientes
supabase db diff

# Push
supabase db push

# Confirmar en Supabase Dashboard
open https://supabase.com/dashboard/project/<prod-ref>/editor

# Deploy app
git push origin main

# Vercel auto-deploys

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  8. MONITOREO                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Ver logs producciÃ³n
open https://supabase.com/dashboard/project/<prod-ref>/logs

# Ver analytics
open https://vercel.com/dashboard/analytics
```

### Workflow Diario

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INICIO DEL DÃA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# 1. Pull Ãºltimos cambios
git pull origin main

# 2. Iniciar Supabase (si no estÃ¡ corriendo)
supabase start

# 3. Aplicar nuevas migrations (si hay)
supabase db reset

# 4. Iniciar dev server
npm run dev

# 5. Abrir Studio
open http://127.0.0.1:54323

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DURANTE EL DÃA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Si cambias DB:
# 1. Edita SQL en Studio O crea migration
# 2. Si usaste Studio, genera migration:
supabase db diff -f changes_20250105

# 3. Aplica
supabase db reset

# Si cambias cÃ³digo:
# - Next.js auto-reload (Fast Refresh)
# - Supabase no requiere restart

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FIN DEL DÃA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# 1. Commit
git add .
git commit -m "feat: ..."
git push

# 2. Detener Supabase (opcional)
supabase stop

# O dejar corriendo para maÃ±ana (recomendado)
# Los contenedores usan poca RAM cuando idle
```

---

## ğŸ—‚ï¸ Migrations: Local vs Cloud

### Â¿QuÃ© son las Migrations?

**Migrations** son archivos SQL que definen cambios en tu schema.

```
supabase/migrations/
â”œâ”€â”€ 20250101000000_initial_schema.sql
â”œâ”€â”€ 20250102120000_add_products.sql
â”œâ”€â”€ 20250103090000_add_rls_policies.sql
â””â”€â”€ 20250105140000_add_restock_rules.sql
```

### Reglas de Oro

1. âœ… **NUNCA editar migrations aplicadas**
   - Las migrations son inmutables
   - Si necesitas cambiar algo, crea nueva migration

2. âœ… **Las migrations son la fuente de verdad**
   - No el schema en Studio
   - No cambios manuales en producciÃ³n

3. âœ… **Siempre usar migrations en local primero**
   - Test local
   - Luego push a cloud

### Crear Migration

```bash
# MÃ©todo 1: Manual
supabase migration new add_inventory_table

# Editar archivo generado
vim supabase/migrations/20250105140523_add_inventory_table.sql

# Escribir SQL:
CREATE TABLE inventory (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  product_id UUID REFERENCES products(id),
  quantity INTEGER NOT NULL DEFAULT 0,
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

# MÃ©todo 2: Desde cambios en Studio
# 1. Hacer cambios en Studio (Table Editor)
# 2. Generar migration desde diff:
supabase db diff -f add_inventory_table

# Supabase auto-genera SQL basado en cambios
```

### Aplicar Migration Local

```bash
# OpciÃ³n A: Reset (recomendado)
supabase db reset

# Lo que hace:
# 1. DROP DATABASE
# 2. CREATE DATABASE
# 3. Aplica TODAS las migrations en orden
# 4. Carga seed.sql (datos de prueba)

# OpciÃ³n B: Aplicar solo nuevas (no recomendado local)
# No hay comando directo, usa reset siempre

# Verificar aplicadas
psql $DATABASE_URL -c "SELECT * FROM supabase_migrations.schema_migrations"
```

### Push a Cloud

```bash
# 1. Link con cloud (primera vez)
supabase link --project-ref azjaehrdzdfgrumbqmuc

# 2. Ver quÃ© migrations faltan en cloud
supabase db diff

# Output:
# Local migrations not in remote:
# - 20250105140523_add_inventory_table.sql

# 3. Push
supabase db push

# âš ï¸ IMPORTANTE:
# - Esto NO hace reset en cloud
# - Solo aplica migrations faltantes
# - Es irreversible
# - Â¡Haz backup primero!

# 4. Confirmar en Dashboard
open https://supabase.com/dashboard/project/azjaehrdzdfgrumbqmuc/editor
```

### Pull desde Cloud

```bash
# Scenario: Alguien mÃ¡s hizo cambios en cloud
# (no recomendado, pero pasa)

# 1. Pull schema
supabase db pull

# Genera nueva migration con diferencias

# 2. Review cambios
git diff supabase/migrations/

# 3. Si OK, commit
git add supabase/migrations/
git commit -m "chore: Sync schema from cloud"

# 4. Aplicar local
supabase db reset
```

### Rollback (Revertir)

```bash
# No hay rollback automÃ¡tico en Supabase
# Debes crear migration manual

# Si aplicaste:
# 20250105_add_column.sql
ALTER TABLE products ADD COLUMN new_field TEXT;

# Crear rollback:
supabase migration new rollback_add_column

# Editar:
ALTER TABLE products DROP COLUMN new_field;

# Aplicar
supabase db reset  # local
supabase db push   # cloud
```

### Estrategia de Migrations

```bash
# âœ… BUENAS PRÃCTICAS

# 1. Migrations pequeÃ±as y frecuentes
# Mal:
# 20250105_big_update.sql (500 lÃ­neas, 10 tablas)

# Bien:
# 20250105_add_products_table.sql
# 20250105_add_products_rls.sql
# 20250105_add_products_indexes.sql

# 2. Nombres descriptivos
# Mal:
# 20250105_changes.sql
# 20250105_fix.sql

# Bien:
# 20250105_add_inventory_tracking.sql
# 20250105_fix_products_rls_policy.sql

# 3. Comentarios explicativos
-- Migration: Add inventory tracking
-- Purpose: Track real-time product quantities
-- Related: Issue #123
-- Author: @username

CREATE TABLE inventory (...);

# 4. Idempotencia (pueden ejecutarse mÃºltiples veces)
-- Mal:
CREATE TABLE products (...);  -- Falla si ya existe

-- Bien:
CREATE TABLE IF NOT EXISTS products (...);

-- O:
DROP TABLE IF EXISTS products;
CREATE TABLE products (...);

# 5. Transacciones
BEGIN;

-- Cambios relacionados
ALTER TABLE products ADD COLUMN stock INTEGER;
CREATE INDEX idx_products_stock ON products(stock);

COMMIT;
```

### Ejemplo Completo

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FEATURE: Agregar sistema de notificaciones
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# 1. Crear migration
supabase migration new add_notifications_system

# 2. Editar: supabase/migrations/20250105_add_notifications_system.sql
-- Tabla de notificaciones
CREATE TABLE notifications (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
  title TEXT NOT NULL,
  message TEXT NOT NULL,
  type TEXT NOT NULL CHECK (type IN ('info', 'warning', 'success', 'error')),
  read BOOLEAN DEFAULT FALSE,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Ãndices para performance
CREATE INDEX idx_notifications_user_id ON notifications(user_id);
CREATE INDEX idx_notifications_created_at ON notifications(created_at DESC);
CREATE INDEX idx_notifications_read ON notifications(read) WHERE read = FALSE;

-- RLS
ALTER TABLE notifications ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can view own notifications"
ON notifications FOR SELECT
TO authenticated
USING (user_id = auth.uid());

CREATE POLICY "Users can update own notifications"
ON notifications FOR UPDATE
TO authenticated
USING (user_id = auth.uid())
WITH CHECK (user_id = auth.uid());

-- FunciÃ³n para marcar como leÃ­das
CREATE OR REPLACE FUNCTION mark_notifications_as_read(notification_ids UUID[])
RETURNS VOID AS $$
BEGIN
  UPDATE notifications
  SET read = TRUE
  WHERE id = ANY(notification_ids)
    AND user_id = auth.uid();
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Trigger para limpiar notificaciones antiguas (> 30 dÃ­as)
CREATE OR REPLACE FUNCTION delete_old_notifications()
RETURNS TRIGGER AS $$
BEGIN
  DELETE FROM notifications
  WHERE created_at < NOW() - INTERVAL '30 days'
    AND read = TRUE;
  RETURN NULL;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_delete_old_notifications
AFTER INSERT ON notifications
EXECUTE FUNCTION delete_old_notifications();

# 3. Aplicar local
supabase db reset

# 4. Verificar
psql $DATABASE_URL
> \d notifications
> SELECT * FROM pg_policies WHERE tablename = 'notifications';

# 5. Seed data (opcional)
# Editar: supabase/seed.sql
INSERT INTO notifications (user_id, title, message, type)
SELECT
  id,
  'Welcome!',
  'Thanks for joining ComerECO',
  'success'
FROM auth.users
LIMIT 5;

# 6. Test en app
# src/lib/api/notifications.ts
export async function getNotifications() {
  const { data } = await supabase
    .from('notifications')
    .select('*')
    .order('created_at', { ascending: false })
  return data
}

# 7. Commit
git add supabase/migrations/20250105_add_notifications_system.sql
git add supabase/seed.sql
git commit -m "feat: Add notifications system"

# 8. Push a cloud cuando estÃ© listo
supabase link --project-ref prod-ref
supabase db push
```

---

## ğŸŒ Puertos y URLs

### Mapa de Puertos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Servicio   â”‚    Puerto      â”‚         URL/Uso             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Kong         â”‚ 54321          â”‚ http://127.0.0.1:54321      â”‚
â”‚ (API Gateway)â”‚                â”‚ Punto de entrada principal  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PostgreSQL   â”‚ 54322          â”‚ postgresql://               â”‚
â”‚              â”‚                â”‚   postgres:postgres@        â”‚
â”‚              â”‚                â”‚   127.0.0.1:54322/postgres  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Studio       â”‚ 54323          â”‚ http://127.0.0.1:54323      â”‚
â”‚ (Dashboard)  â”‚                â”‚ UI de administraciÃ³n        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Mailpit      â”‚ 54324          â”‚ http://127.0.0.1:54324      â”‚
â”‚ (Email test) â”‚                â”‚ Ver emails capturados       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Logflare     â”‚ 54327          â”‚ http://127.0.0.1:54327      â”‚
â”‚ (Analytics)  â”‚                â”‚ Dashboard de logs           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PostgREST    â”‚ 3000 (interno) â”‚ Via Kong: /rest/v1/*        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GoTrue       â”‚ 9999 (interno) â”‚ Via Kong: /auth/v1/*        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Realtime     â”‚ 4000 (interno) â”‚ Via Kong: /realtime/v1/*    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Storage      â”‚ 5000 (interno) â”‚ Via Kong: /storage/v1/*     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### URLs por Funcionalidad

```javascript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// REST API (PostgREST)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
const API_URL = 'http://127.0.0.1:54321/rest/v1'

// Listar productos
fetch(`${API_URL}/products`, {
  headers: {
    'apikey': ANON_KEY,
    'Authorization': `Bearer ${token}`
  }
})

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Authentication (GoTrue)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
const AUTH_URL = 'http://127.0.0.1:54321/auth/v1'

// Signup
fetch(`${AUTH_URL}/signup`, {
  method: 'POST',
  headers: { 'apikey': ANON_KEY },
  body: JSON.stringify({ email, password })
})

// Login
fetch(`${AUTH_URL}/token?grant_type=password`, {
  method: 'POST',
  headers: { 'apikey': ANON_KEY },
  body: JSON.stringify({ email, password })
})

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Storage
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
const STORAGE_URL = 'http://127.0.0.1:54321/storage/v1'

// Upload
const formData = new FormData()
formData.append('file', file)

fetch(`${STORAGE_URL}/object/bucket-name/path/file.jpg`, {
  method: 'POST',
  headers: {
    'apikey': ANON_KEY,
    'Authorization': `Bearer ${token}`
  },
  body: formData
})

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Realtime (WebSocket)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
const WS_URL = 'ws://127.0.0.1:54321/realtime/v1/websocket'

const socket = new WebSocket(WS_URL)

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// GraphQL
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
const GRAPHQL_URL = 'http://127.0.0.1:54321/graphql/v1'

fetch(GRAPHQL_URL, {
  method: 'POST',
  headers: {
    'apikey': ANON_KEY,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    query: `
      query {
        productsCollection {
          edges {
            node {
              id
              name
              price
            }
          }
        }
      }
    `
  })
})
```

### ConfiguraciÃ³n en .env.local

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LOCAL DEVELOPMENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
NEXT_PUBLIC_SUPABASE_URL=http://127.0.0.1:54321
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJhbGc...
SUPABASE_SERVICE_ROLE_KEY=eyJhbGc...
DATABASE_URL=postgresql://postgres:postgres@127.0.0.1:54322/postgres

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PRODUCTION (Vercel)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
NEXT_PUBLIC_SUPABASE_URL=https://azjaehrdzdfgrumbqmuc.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJhbGc...
SUPABASE_SERVICE_ROLE_KEY=eyJhbGc...
DATABASE_URL=postgresql://postgres.[PASSWORD]@db.azjaehrdzdfgrumbqmuc.supabase.co:5432/postgres
```

---

## ğŸ’¡ Casos de Uso PrÃ¡cticos

### Caso 1: Desarrollar Feature Completo (RLS Testing)

**Objetivo:** Agregar feature de "favoritos" con RLS

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 1: Setup Local
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
supabase start
open http://127.0.0.1:54323

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 2: Crear Schema
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
supabase migration new add_favorites

# Editar migration:
CREATE TABLE favorites (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
  product_id UUID REFERENCES products(id) ON DELETE CASCADE,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(user_id, product_id)
);

ALTER TABLE favorites ENABLE ROW LEVEL SECURITY;

-- Policy: Ver solo propios favoritos
CREATE POLICY "Users can view own favorites"
ON favorites FOR SELECT
TO authenticated
USING (user_id = auth.uid());

-- Policy: Agregar solo a sÃ­ mismo
CREATE POLICY "Users can insert own favorites"
ON favorites FOR INSERT
TO authenticated
WITH CHECK (user_id = auth.uid());

-- Policy: Eliminar solo propios
CREATE POLICY "Users can delete own favorites"
ON favorites FOR DELETE
TO authenticated
USING (user_id = auth.uid());

# Aplicar
supabase db reset

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 3: Crear Usuarios de Prueba
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
psql $DATABASE_URL

INSERT INTO auth.users (instance_id, id, aud, role, email, encrypted_password, email_confirmed_at)
VALUES
  ('00000000-0000-0000-0000-000000000000', '11111111-1111-1111-1111-111111111111', 'authenticated', 'authenticated', 'user1@test.com', crypt('password', gen_salt('bf')), NOW()),
  ('00000000-0000-0000-0000-000000000000', '22222222-2222-2222-2222-222222222222', 'authenticated', 'authenticated', 'user2@test.com', crypt('password', gen_salt('bf')), NOW());

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 4: Test RLS Manual
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- Simular user1
SET LOCAL role = 'authenticated';
SET LOCAL request.jwt.claim.sub = '11111111-1111-1111-1111-111111111111';

-- Agregar favorito
INSERT INTO favorites (user_id, product_id)
VALUES ('11111111-1111-1111-1111-111111111111', (SELECT id FROM products LIMIT 1));

-- Ver favoritos (debe ver 1)
SELECT * FROM favorites;

-- Intentar ver favoritos de user2 (debe retornar vacÃ­o)
SET LOCAL request.jwt.claim.sub = '22222222-2222-2222-2222-222222222222';
SELECT * FROM favorites;  -- 0 resultados âœ…

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 5: Desarrollar API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# src/lib/api/favorites.ts
export async function addFavorite(productId: string) {
  const { data, error } = await supabase
    .from('favorites')
    .insert({ product_id: productId })
    .select()
    .single()

  if (error) throw error
  return data
}

export async function getFavorites() {
  const { data } = await supabase
    .from('favorites')
    .select('*, products(*)')
  return data
}

export async function removeFavorite(productId: string) {
  await supabase
    .from('favorites')
    .delete()
    .eq('product_id', productId)
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 6: Test en App
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Terminal 2:
npm run dev

# Browser: http://localhost:3000
# 1. Login como user1@test.com
# 2. Agregar favorito
# 3. Verificar aparece en lista

# Studio: Ver queries ejecutados
open http://127.0.0.1:54323/project/default/logs/explorer

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 7: Deploy
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
git add .
git commit -m "feat: Add favorites system"
git push

supabase db push  # Push migration a cloud
```

---

### Caso 2: Debugging Query Lento

**Objetivo:** Identificar y resolver query lento

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 1: Detectar Query Lento
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# En tu app, notas que listar requisitions toma >2s

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 2: Ver Query en Studio
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
open http://127.0.0.1:54323/project/default/logs/explorer

# Buscar query lento
# Filter: duration > 1000ms

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 3: Analizar con EXPLAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
psql $DATABASE_URL

EXPLAIN ANALYZE
SELECT
  r.*,
  c.name as company_name,
  p.name as project_name,
  u.email as created_by_email
FROM requisitions r
JOIN companies c ON r.company_id = c.id
JOIN projects p ON r.project_id = p.id
JOIN auth.users u ON r.created_by = u.id
WHERE r.company_id = '...'
ORDER BY r.created_at DESC;

# Output muestra:
# - Seq Scan on requisitions (LENTO) âŒ
# - No usa Ã­ndices

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 4: Agregar Ãndices
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
supabase migration new add_requisitions_indexes

# Editar:
CREATE INDEX idx_requisitions_company_id ON requisitions(company_id);
CREATE INDEX idx_requisitions_created_at ON requisitions(created_at DESC);
CREATE INDEX idx_requisitions_company_created ON requisitions(company_id, created_at DESC);

# Aplicar
supabase db reset

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 5: Verificar Mejora
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EXPLAIN ANALYZE
-- mismo query

# Output ahora muestra:
# - Index Scan using idx_requisitions_company_created âœ…
# - Execution Time: 12ms (antes: 2000ms)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 6: Test en App
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Refrescar pÃ¡gina
# Listar requisitions ahora <100ms

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 7: Deploy
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
git add supabase/migrations/
git commit -m "perf: Add indexes for requisitions queries"
supabase db push
```

---

### Caso 3: Sincronizar Schema entre Devs

**Objetivo:** Dev B quiere los cambios de Dev A

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SCENARIO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Dev A creÃ³ nueva tabla "inventory"
# Dev A hizo push a main
# Dev B necesita sincronizar

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DEV B: Pull Changes
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# 1. Pull cÃ³digo
git pull origin main

# 2. Ver nuevas migrations
ls supabase/migrations/
# Output:
# - 20250105_add_inventory.sql (NUEVA)

# 3. Aplicar migrations
supabase db reset

# Output:
# Applying migration 20250105_add_inventory.sql...
# âœ“ Migration applied successfully

# 4. Verificar
psql $DATABASE_URL -c "\d inventory"

# 5. Continuar desarrollo normalmente
npm run dev
```

---

### Caso 4: Testing de Edge Functions

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 1: Crear Function
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
supabase functions new send-notification

# Editar: supabase/functions/send-notification/index.ts
import { serve } from 'https://deno.land/std@0.177.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

serve(async (req) => {
  const { userId, message } = await req.json()

  const supabase = createClient(
    Deno.env.get('SUPABASE_URL')!,
    Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
  )

  // Crear notificaciÃ³n en DB
  await supabase
    .from('notifications')
    .insert({
      user_id: userId,
      title: 'New Notification',
      message: message,
      type: 'info'
    })

  return new Response(JSON.stringify({ success: true }))
})

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 2: Deploy Local
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
supabase functions deploy send-notification

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 3: Test
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
curl -X POST http://127.0.0.1:54321/functions/v1/send-notification \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer ${ANON_KEY}" \
  -d '{"userId":"11111111-1111-1111-1111-111111111111","message":"Hello!"}'

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 4: Ver Logs
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
supabase functions logs send-notification --tail

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 5: Verificar en DB
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
psql $DATABASE_URL -c "SELECT * FROM notifications ORDER BY created_at DESC LIMIT 1"
```

---

## ğŸ› Troubleshooting

### Problema 1: Supabase no inicia

```bash
# SÃ­ntomas:
supabase start
# Error: Cannot connect to Docker daemon

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOLUCIÃ“N 1: Docker no estÃ¡ corriendo
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
sudo systemctl start docker    # Linux
open -a Docker                  # Mac

# Verificar
docker ps

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOLUCIÃ“N 2: Permisos
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
sudo usermod -aG docker $USER
newgrp docker

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOLUCIÃ“N 3: Puertos ocupados
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ver quÃ© usa puerto 54321
sudo lsof -i :54321

# Matar proceso
sudo kill -9 <PID>

# O cambiar puerto en config.toml
[api]
port = 54321  â†’ port = 54421

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOLUCIÃ“N 4: Reset completo
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
supabase stop
docker system prune -a --volumes  # âš ï¸ Elimina TODO Docker
supabase start
```

---

### Problema 2: Migration Falla

```bash
# SÃ­ntomas:
supabase db reset
# Error: migration 20250105_xxx.sql failed

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOLUCIÃ“N 1: Ver error especÃ­fico
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
supabase db reset 2>&1 | grep -A 10 "ERROR"

# Errores comunes:
# - "relation already exists" â†’ DROP IF EXISTS primero
# - "column does not exist" â†’ Typo en nombre
# - "syntax error" â†’ SQL invÃ¡lido

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOLUCIÃ“N 2: Test migration manualmente
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
psql $DATABASE_URL < supabase/migrations/20250105_xxx.sql

# Ver lÃ­nea exacta con error

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOLUCIÃ“N 3: Dividir migration grande
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Si migration tiene 500 lÃ­neas, dividir en partes
# Ejecutar parte por parte para encontrar error

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOLUCIÃ“N 4: Skip migration (Ãºltimo recurso)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Marcar como aplicada sin ejecutar
psql $DATABASE_URL -c "
  INSERT INTO supabase_migrations.schema_migrations (version)
  VALUES ('20250105_xxx');
"
```

---

### Problema 3: RLS No Funciona

```bash
# SÃ­ntomas:
# - Queries retornan datos de otros usuarios
# - O retornan vacÃ­o cuando no deberÃ­a

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DEBUG PASO A PASO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# 1. Verificar RLS estÃ¡ habilitado
psql $DATABASE_URL -c "
  SELECT tablename, rowsecurity
  FROM pg_tables
  WHERE schemaname = 'public'
    AND tablename = 'tu_tabla';
"
# rowsecurity debe ser 't' (true)

# 2. Ver policies
psql $DATABASE_URL -c "
  SELECT *
  FROM pg_policies
  WHERE tablename = 'tu_tabla';
"

# 3. Test manual con role
psql $DATABASE_URL
SET LOCAL role = 'authenticated';
SET LOCAL request.jwt.claim.sub = '<user-id>';
SELECT * FROM tu_tabla;

# 4. Si retorna vacÃ­o, policy estÃ¡ muy restrictivo
# Si retorna todo, falta policy

# 5. Ver query ejecutado por PostgREST
docker logs supabase_rest_COMERECO-WEBAPP -f
# Hacer request desde app
# Ver SQL generado

# 6. Copiar SQL y ejecutar manual
psql $DATABASE_URL
-- Pegar SQL
EXPLAIN (ANALYZE, VERBOSE, BUFFERS)
<SQL copiado>;
```

---

### Problema 4: Containers Usan Mucha RAM

```bash
# Ver uso
docker stats

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOLUCIÃ“N 1: Limit memoria
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Editar: ~/.config/supabase/config.toml (No existe en Supabase)
# Docker Compose no expone limits fÃ¡cilmente

# Alternativa: Usar Docker Desktop limits
# Settings â†’ Resources â†’ Memory Limit

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOLUCIÃ“N 2: Stop cuando no uses
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
supabase stop  # RAM liberada inmediatamente

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOLUCIÃ“N 3: Cleanup logs
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
docker exec supabase_db_COMERECO-WEBAPP psql -U postgres -c "
  TRUNCATE supabase_migrations.seed_files;
"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOLUCIÃ“N 4: Disable analytics local
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Analytics (Logflare) usa ~500MB
# Editar supabase/config.toml:
[analytics]
enabled = false

supabase stop
supabase start
```

---

### Problema 5: Datos Desincronizados

```bash
# Scenario: Studio muestra datos viejos

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOLUCIÃ“N 1: Refresh cache
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# En Studio: CMD+R (Mac) o CTRL+R (Windows)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOLUCIÃ“N 2: Verificar directamente en DB
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
psql $DATABASE_URL -c "SELECT * FROM tu_tabla"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOLUCIÃ“N 3: Restart services
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
supabase restart

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SOLUCIÃ“N 4: Full reset
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
supabase db reset
```

---

## âœ… Mejores PrÃ¡cticas

### 1. GestiÃ³n de Migrations

```bash
# âœ… DO
# - Crear migrations pequeÃ±as y frecuentes
supabase migration new add_single_table

# - Nombres descriptivos
add_inventory_tracking.sql
fix_products_rls_recursion.sql

# - Comentarios explicativos
-- Migration: Add inventory tracking
-- Purpose: Real-time stock management
-- Related: Issue #123

# - Idempotencia
CREATE TABLE IF NOT EXISTS ...
DROP POLICY IF EXISTS ...

# - Transacciones
BEGIN;
-- cambios relacionados
COMMIT;

# âŒ DON'T
# - Editar migrations aplicadas
# - Nombres genÃ©ricos: changes.sql, fix.sql
# - Migrations gigantes (>200 lÃ­neas)
# - Olvidar comentarios
```

### 2. Desarrollo Local First

```bash
# âœ… DO
# 1. Desarrollar en local
supabase start
# 2. Test exhaustivo
# 3. Commit
git push
# 4. Deploy a cloud
supabase db push

# âŒ DON'T
# 1. Hacer cambios directo en cloud Dashboard
# 2. Olvidar pull a local
# 3. DesincronizaciÃ³n entre local y cloud
```

### 3. Manejo de Datos Sensibles

```bash
# âœ… DO
# - Service role key SOLO en server
# .env.local (no commitear):
SUPABASE_SERVICE_ROLE_KEY=xxx

# - Anon key puede ser pÃºblica
NEXT_PUBLIC_SUPABASE_ANON_KEY=xxx

# - RLS protege datos
# Anon key + RLS = Seguro

# âŒ DON'T
# - Service key en frontend
# - Commitear .env.local
# - Confiar en "security through obscurity"
```

### 4. Performance

```bash
# âœ… DO
# - Ãndices en columnas filtradas
CREATE INDEX idx_products_company ON products(company_id);

# - LÃ­mite en queries
.select('*').limit(50)

# - Pagination
.range(0, 49)

# âŒ DON'T
# - SELECT * en tablas grandes sin lÃ­mite
# - Joins innecesarios
# - Filtros en columnas sin Ã­ndices
```

### 5. Testing

```bash
# âœ… DO
# - Test RLS manualmente
SET LOCAL role = 'authenticated';
SET LOCAL request.jwt.claim.sub = '<user-id>';

# - Seed data representativa
# supabase/seed.sql con casos reales

# - Test performance
EXPLAIN ANALYZE <query>

# âŒ DON'T
# - Asumir RLS funciona sin test
# - Solo test con Service Role (bypasses RLS)
# - Ignorar performance hasta producciÃ³n
```

---

## ğŸ“Š ComparaciÃ³n: Local vs Cloud

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Aspecto       â”‚  Local (Docker)   â”‚   Cloud           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Costo           â”‚ Gratis            â”‚ $25/mes (Pro)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Latencia        â”‚ <5ms              â”‚ 50-200ms          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Internet        â”‚ No necesario      â”‚ Requerido         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LÃ­mites API     â”‚ Ilimitado         â”‚ 500 req/s (Pro)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Storage         â”‚ Disco local       â”‚ 100GB (Pro)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Backups         â”‚ Manual            â”‚ AutomÃ¡tico diario â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Escalabilidad   â”‚ Limitada a PC     â”‚ Auto-scale        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Uptime          â”‚ Cuando PC on      â”‚ 99.9% SLA         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Uso ideal       â”‚ Desarrollo        â”‚ ProducciÃ³n        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Database        â”‚ PostgreSQL 17     â”‚ PostgreSQL 15     â”‚
â”‚ Version         â”‚ (mÃ¡s reciente)    â”‚ (mÃ¡s estable)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CuÃ¡ndo Usar QuÃ©

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# USA LOCAL para:
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Desarrollo diario
âœ… Testing de features
âœ… ExperimentaciÃ³n (sin miedo a romper)
âœ… Debugging profundo
âœ… Desarrollo sin internet
âœ… Crear migrations
âœ… CI/CD pipelines
âœ… Onboarding nuevos devs

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# USA CLOUD para:
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… ProducciÃ³n
âœ… Staging
âœ… Demos a clientes
âœ… Testing con usuarios reales
âœ… Datos persistentes
âœ… ColaboraciÃ³n en tiempo real
âœ… Webhooks externos
âœ… Integraciones (n8n â†’ BIND)
```

---

## â“ FAQ

### Â¿Debo commitear `.env.local`?

âŒ **NO.** `.env.local` debe estar en `.gitignore`

```bash
# .gitignore
.env.local
.env*.local

# Commitear .env.example como template
```

### Â¿Puedo usar Supabase Cloud sin local?

âœ… **SÃ**, pero no es recomendado. PerderÃ­as:
- Testing rÃ¡pido
- Desarrollo sin internet
- ExperimentaciÃ³n segura

### Â¿CÃ³mo sincronizo DB entre local y cloud?

```bash
# Cloud â†’ Local
supabase db pull  # Trae schema

# Local â†’ Cloud
supabase db push  # Sube migrations
```

### Â¿Los datos de local se sincronizan a cloud?

âŒ **NO**. Solo el **schema** (migrations) se sincroniza.

Datos son independientes:
- Local: Datos de prueba (seed.sql)
- Cloud: Datos reales de usuarios

### Â¿CÃ³mo backup mi DB local?

```bash
# Backup completo
pg_dump $DATABASE_URL > backup.sql

# Restore
psql $DATABASE_URL < backup.sql

# O usar supabase CLI
supabase db dump -f backup.sql
```

### Â¿Puedo correr mÃºltiples proyectos Supabase local?

âœ… **SÃ**, pero en diferentes puertos

```bash
# Proyecto 1
cd ~/project1
supabase start  # Usa puertos 54321, 54322, 54323...

# Proyecto 2
cd ~/project2
supabase start  # Usa puertos 54421, 54422, 54423...
```

### Â¿QuÃ© pasa si elimino volÃºmenes Docker?

âš ï¸ **Pierdes todos los datos locales**

```bash
docker volume rm supabase_db_COMERECO-WEBAPP
# âŒ Todos los datos eliminados

# SoluciÃ³n:
supabase db reset  # Re-aplica migrations + seed
```

### Â¿CÃ³mo actualizar Supabase Local?

```bash
# Actualizar CLI
npm update -g supabase

# Actualizar imÃ¡genes Docker
supabase stop
docker pull public.ecr.aws/supabase/postgres:latest
# (Supabase CLI descarga automÃ¡ticamente)
supabase start
```

### Â¿Puedo usar otro DB en lugar de PostgreSQL local?

âŒ **NO**. Supabase Local requiere PostgreSQL 17 con extensiones especÃ­ficas.

### Â¿CÃ³mo debuggear RLS polÃ­ticas?

```sql
-- Ver si RLS estÃ¡ habilitado
SELECT tablename, rowsecurity
FROM pg_tables
WHERE schemaname = 'public';

-- Ver policies
SELECT * FROM pg_policies WHERE tablename = 'tu_tabla';

-- Test manual
SET LOCAL role = 'authenticated';
SET LOCAL request.jwt.claim.sub = '<user-id>';
SELECT * FROM tu_tabla;
```

### Â¿CÃ³mo hacer que migrations sean reversibles?

Crear par de migrations:

```bash
# Up migration
supabase migration new add_column
# Contenido:
ALTER TABLE products ADD COLUMN new_field TEXT;

# Down migration (manual)
supabase migration new rollback_add_column
# Contenido:
ALTER TABLE products DROP COLUMN new_field;
```

---

## ğŸ“š Recursos Adicionales

### DocumentaciÃ³n Oficial

- [Supabase Docs](https://supabase.com/docs)
- [Supabase CLI Reference](https://supabase.com/docs/reference/cli)
- [Docker Docs](https://docs.docker.com)
- [PostgreSQL Docs](https://www.postgresql.org/docs)

### GuÃ­as Relacionadas

- [GUIA_PRUEBAS_LOCALES.md](./GUIA_PRUEBAS_LOCALES.md) - Testing local
- [GUIA_BEST_PRACTICES_SUPABASE.md](./GUIA_BEST_PRACTICES_SUPABASE.md) - Mejores prÃ¡cticas
- [REFERENCIA_BD_SUPABASE.md](./REFERENCIA_BD_SUPABASE.md) - Schema completo

### Comunidad

- [Supabase Discord](https://discord.supabase.com)
- [GitHub Discussions](https://github.com/supabase/supabase/discussions)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/supabase)

---

## ğŸ“ Changelog

### v1.0 - 2025-11-05
- âœ… GuÃ­a inicial completa
- âœ… DocumentaciÃ³n de 12 servicios
- âœ… Comandos esenciales
- âœ… Casos de uso prÃ¡cticos
- âœ… Troubleshooting exhaustivo
- âœ… FAQ completo

---

**Â¿Dudas o sugerencias?** Abre un issue o contacta al equipo de desarrollo.

**Ãšltima actualizaciÃ³n:** 2025-11-05
